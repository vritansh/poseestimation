{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fKUiSc5CmQFX"
   },
   "source": [
    "# Summary:  Research based code file for performing image classification using CNN and custom model architecture. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l6keQov5kzYZ"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import zipfile\n",
    "from google.colab import drive\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from PIL import ImageFile\n",
    "from tensorflow.keras.models import Sequential, model_from_json\n",
    "from tensorflow.keras.layers import Dense\n",
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x5DT0og65h-I"
   },
   "outputs": [],
   "source": [
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eVH6yenemRxG"
   },
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "for gpu in gpus:\n",
    "  tf.config.experimental.list_physical_devices(gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cilg1aDwmpG_"
   },
   "outputs": [],
   "source": [
    "#Adding zip \n",
    "zip_paths = ['/content/drive/MyDrive/archive (26).zip']\n",
    "train_data = tf.constant(zip_paths)\n",
    "train_data = tf.data.Dataset.from_tensor_slices(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VG1BdnognlId"
   },
   "outputs": [],
   "source": [
    "# drive.mount('/content/drive/')\n",
    "zip_ref = zipfile.ZipFile(\"/content/drive/MyDrive/archive (26).zip\", 'r')\n",
    "zip_ref.extractall(\"/content/sample_data\")\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-ztFeU1lnl5M",
    "outputId": "dd99ed36-5a09-4f16-8e91-ee0c4b5b1bdd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 866 images belonging to 5 classes.\n",
      "Found 215 images belonging to 5 classes.\n",
      "Found 470 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "data_dir_train = \"/content/sample_data/DATASET/TRAIN\"\n",
    "data_dir_test = \"/content/sample_data/DATASET/TEST\"\n",
    "\n",
    "size = 256\n",
    "img_gen_train = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1.0 / 255,\n",
    "    validation_split=0.2\n",
    "    # rotation_range=20,\n",
    "    # width_shift_range=0.2,\n",
    "    # height_shift_range=0.2,\n",
    "    # vertical_flip=True,\n",
    ")\n",
    "\n",
    "X_train = img_gen_train.flow_from_directory(data_dir_train,\n",
    "                                        batch_size=32,\n",
    "                                        target_size=(size, size),\n",
    "                                        class_mode='categorical',\n",
    "                                        color_mode='rgb',\n",
    "                                        subset='training'\n",
    "                                        )\n",
    "\n",
    "X_val = img_gen_train.flow_from_directory(data_dir_train,\n",
    "                                        batch_size=32,\n",
    "                                        target_size=(size, size),\n",
    "                                        class_mode='categorical',\n",
    "                                        color_mode='rgb',\n",
    "                                        subset='validation'\n",
    "                                        )\n",
    "\n",
    "img_gen_test = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1.0 / 255,\n",
    "    # rotation_range=20,\n",
    "    # width_shift_range=0.2,\n",
    "    # height_shift_range=0.2,\n",
    "    # vertical_flip=True,\n",
    ")\n",
    "\n",
    "X_test = img_gen_test.flow_from_directory(data_dir_test,\n",
    "                                        batch_size=32,\n",
    "                                        target_size=(256, 256),\n",
    "                                        class_mode='categorical',\n",
    "                                        color_mode='rgb'\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "D1ZWXNgFr0pQ",
    "outputId": "d3114b25-818c-45f9-cf53-947863e9875b"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Showing a random image\n",
    "plt.imshow(X_train[1][0][22])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z_GI3WFKxOnH",
    "outputId": "50ad7179-0d54-4e67-f396-18c9ee29df97"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'downdog': 0, 'goddess': 1, 'plank': 2, 'tree': 3, 'warrior2': 4}\n",
      "{'downdog': 0, 'goddess': 1, 'plank': 2, 'tree': 3, 'warrior2': 4}\n"
     ]
    }
   ],
   "source": [
    "print(X_train.class_indices)\n",
    "print(X_test.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XKO-dVBVoQ67"
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        layers.Conv2D(filters=16,kernel_size=(5,5),strides=1, activation=\"relu\",name = \"ConvolutionLayer1\",input_shape=(256, 256, 3)),\n",
    "        layers.MaxPool2D(),\n",
    "\n",
    "        layers.Conv2D(filters=32,kernel_size=(5,5),strides=1, activation=\"relu\",name = \"ConvolutionLayer2\"),\n",
    "        layers.MaxPool2D(),\n",
    "     \n",
    "        layers.Conv2D(filters=16,kernel_size=(5,5),strides=1, activation=\"relu\",name = \"ConvolutionLayer3\"),\n",
    "        layers.MaxPool2D(),\n",
    "     \n",
    "        layers.Conv2D(filters=32,kernel_size=(5,5),strides=1, activation=\"relu\",name = \"ConvolutionLayer4\"),\n",
    "        layers.MaxPool2D(),\n",
    "     \n",
    "        layers.Conv2D(filters=16,kernel_size=(5,5),strides=1, activation=\"relu\",name = \"ConvolutionLayer5\"),\n",
    "        layers.MaxPool2D(),\n",
    "     \n",
    "        layers.GlobalAveragePooling2D(),\n",
    "     \n",
    "        layers.Dense(112, activation=\"relu\", name=\"layer1\"),\n",
    "        layers.Dropout(.2),\n",
    "        layers.Dense(256, activation=\"relu\", name=\"layer2\"),\n",
    "        layers.Dropout(.2),\n",
    "        layers.Dense(112, activation=\"relu\", name=\"layer3\"),\n",
    "\n",
    "        # layers.Dense(32, activation=\"relu\", name=\"layer2\"),      \n",
    "        layers.Dense(5 , name=\"output\", activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zwx8Ln4YrJhX",
    "outputId": "7b5474ff-6929-44ff-ce3a-b166e7618e0c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " ConvolutionLayer1 (Conv2D)  (None, 252, 252, 16)      1216      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 126, 126, 16)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " ConvolutionLayer2 (Conv2D)  (None, 122, 122, 32)      12832     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 61, 61, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " ConvolutionLayer3 (Conv2D)  (None, 57, 57, 16)        12816     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 28, 28, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " ConvolutionLayer4 (Conv2D)  (None, 24, 24, 32)        12832     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 12, 12, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " ConvolutionLayer5 (Conv2D)  (None, 8, 8, 16)          12816     \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 4, 4, 16)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 16)               0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " layer1 (Dense)              (None, 112)               1904      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 112)               0         \n",
      "                                                                 \n",
      " layer2 (Dense)              (None, 256)               28928     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " layer3 (Dense)              (None, 112)               28784     \n",
      "                                                                 \n",
      " output (Dense)              (None, 5)                 565       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 112,693\n",
      "Trainable params: 112,693\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wjlL2aQ1BciS"
   },
   "source": [
    "Train Deep Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ECE_vpKK0LY3",
    "outputId": "430d7ab7-e2b5-4b7d-92ba-0107e495caa3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "14/28 [==============>...............] - ETA: 6s - loss: 1.6102 - accuracy: 0.2201"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 26s 607ms/step - loss: 1.6027 - accuracy: 0.2344 - val_loss: 1.5942 - val_accuracy: 0.2326\n",
      "Epoch 2/40\n",
      "28/28 [==============================] - 16s 565ms/step - loss: 1.5999 - accuracy: 0.2309 - val_loss: 1.5998 - val_accuracy: 0.2465\n",
      "Epoch 3/40\n",
      "28/28 [==============================] - 17s 618ms/step - loss: 1.5979 - accuracy: 0.2460 - val_loss: 1.5936 - val_accuracy: 0.2465\n",
      "Epoch 4/40\n",
      "28/28 [==============================] - 17s 597ms/step - loss: 1.5942 - accuracy: 0.2460 - val_loss: 1.5927 - val_accuracy: 0.2465\n",
      "Epoch 5/40\n",
      "28/28 [==============================] - 16s 566ms/step - loss: 1.5951 - accuracy: 0.2471 - val_loss: 1.5898 - val_accuracy: 0.2465\n",
      "Epoch 6/40\n",
      "28/28 [==============================] - 17s 610ms/step - loss: 1.5775 - accuracy: 0.2390 - val_loss: 1.5905 - val_accuracy: 0.2326\n",
      "Epoch 7/40\n",
      "28/28 [==============================] - 16s 569ms/step - loss: 1.5817 - accuracy: 0.2367 - val_loss: 1.5604 - val_accuracy: 0.2465\n",
      "Epoch 8/40\n",
      "28/28 [==============================] - 16s 566ms/step - loss: 1.5430 - accuracy: 0.3048 - val_loss: 1.5335 - val_accuracy: 0.3442\n",
      "Epoch 9/40\n",
      "28/28 [==============================] - 17s 609ms/step - loss: 1.5178 - accuracy: 0.3337 - val_loss: 1.5561 - val_accuracy: 0.2884\n",
      "Epoch 10/40\n",
      "28/28 [==============================] - 16s 558ms/step - loss: 1.5001 - accuracy: 0.3383 - val_loss: 1.4655 - val_accuracy: 0.3767\n",
      "Epoch 11/40\n",
      "28/28 [==============================] - 16s 558ms/step - loss: 1.4853 - accuracy: 0.3303 - val_loss: 1.5973 - val_accuracy: 0.2326\n",
      "Epoch 12/40\n",
      "28/28 [==============================] - 16s 570ms/step - loss: 1.5827 - accuracy: 0.2598 - val_loss: 1.4873 - val_accuracy: 0.3395\n",
      "Epoch 13/40\n",
      "28/28 [==============================] - 18s 669ms/step - loss: 1.4863 - accuracy: 0.3314 - val_loss: 1.3985 - val_accuracy: 0.3581\n",
      "Epoch 14/40\n",
      "28/28 [==============================] - 16s 560ms/step - loss: 1.4270 - accuracy: 0.3718 - val_loss: 1.4003 - val_accuracy: 0.4558\n",
      "Epoch 15/40\n",
      "28/28 [==============================] - 16s 564ms/step - loss: 1.3621 - accuracy: 0.4157 - val_loss: 1.2680 - val_accuracy: 0.4837\n",
      "Epoch 16/40\n",
      "28/28 [==============================] - 17s 621ms/step - loss: 1.2473 - accuracy: 0.4954 - val_loss: 1.1403 - val_accuracy: 0.5116\n",
      "Epoch 17/40\n",
      "28/28 [==============================] - 16s 549ms/step - loss: 1.2303 - accuracy: 0.4919 - val_loss: 1.1605 - val_accuracy: 0.5256\n",
      "Epoch 18/40\n",
      "28/28 [==============================] - 16s 568ms/step - loss: 1.0642 - accuracy: 0.5589 - val_loss: 1.0544 - val_accuracy: 0.6000\n",
      "Epoch 19/40\n",
      "28/28 [==============================] - 17s 620ms/step - loss: 1.0169 - accuracy: 0.5808 - val_loss: 1.1101 - val_accuracy: 0.5256\n",
      "Epoch 20/40\n",
      "28/28 [==============================] - 16s 574ms/step - loss: 1.0430 - accuracy: 0.5797 - val_loss: 1.0565 - val_accuracy: 0.5814\n",
      "Epoch 21/40\n",
      "28/28 [==============================] - 16s 568ms/step - loss: 0.9823 - accuracy: 0.6132 - val_loss: 1.0234 - val_accuracy: 0.6233\n",
      "Epoch 22/40\n",
      "28/28 [==============================] - 17s 616ms/step - loss: 1.0369 - accuracy: 0.6051 - val_loss: 1.0074 - val_accuracy: 0.5953\n",
      "Epoch 23/40\n",
      "28/28 [==============================] - 16s 558ms/step - loss: 0.9003 - accuracy: 0.6282 - val_loss: 0.9133 - val_accuracy: 0.6558\n",
      "Epoch 24/40\n",
      "28/28 [==============================] - 16s 567ms/step - loss: 0.8158 - accuracy: 0.6582 - val_loss: 0.8521 - val_accuracy: 0.6791\n",
      "Epoch 25/40\n",
      "28/28 [==============================] - 16s 560ms/step - loss: 0.7399 - accuracy: 0.7136 - val_loss: 0.7809 - val_accuracy: 0.7256\n",
      "Epoch 26/40\n",
      "28/28 [==============================] - 19s 664ms/step - loss: 0.6281 - accuracy: 0.7702 - val_loss: 0.8171 - val_accuracy: 0.7070\n",
      "Epoch 27/40\n",
      "28/28 [==============================] - 16s 571ms/step - loss: 0.5782 - accuracy: 0.7864 - val_loss: 0.8758 - val_accuracy: 0.6326\n",
      "Epoch 28/40\n",
      "28/28 [==============================] - 16s 577ms/step - loss: 0.5705 - accuracy: 0.7898 - val_loss: 0.8336 - val_accuracy: 0.7442\n",
      "Epoch 29/40\n",
      "28/28 [==============================] - 17s 618ms/step - loss: 0.4835 - accuracy: 0.8279 - val_loss: 0.8671 - val_accuracy: 0.7674\n",
      "Epoch 30/40\n",
      "28/28 [==============================] - 16s 572ms/step - loss: 0.5084 - accuracy: 0.8025 - val_loss: 0.9698 - val_accuracy: 0.7163\n",
      "Epoch 31/40\n",
      "28/28 [==============================] - 16s 561ms/step - loss: 0.5089 - accuracy: 0.8291 - val_loss: 0.8877 - val_accuracy: 0.7721\n",
      "Epoch 32/40\n",
      "28/28 [==============================] - 17s 593ms/step - loss: 0.4732 - accuracy: 0.8256 - val_loss: 0.8280 - val_accuracy: 0.7488\n",
      "Epoch 33/40\n",
      "28/28 [==============================] - 16s 571ms/step - loss: 0.3810 - accuracy: 0.8591 - val_loss: 0.8337 - val_accuracy: 0.7535\n",
      "Epoch 34/40\n",
      "28/28 [==============================] - 16s 564ms/step - loss: 0.2958 - accuracy: 0.8972 - val_loss: 0.8366 - val_accuracy: 0.7860\n",
      "Epoch 35/40\n",
      "28/28 [==============================] - 16s 562ms/step - loss: 0.2313 - accuracy: 0.9307 - val_loss: 0.9564 - val_accuracy: 0.7814\n",
      "Epoch 36/40\n",
      "28/28 [==============================] - 17s 618ms/step - loss: 0.2867 - accuracy: 0.8938 - val_loss: 0.8683 - val_accuracy: 0.7535\n",
      "Epoch 37/40\n",
      "28/28 [==============================] - 16s 567ms/step - loss: 0.2818 - accuracy: 0.9030 - val_loss: 0.9506 - val_accuracy: 0.7535\n",
      "Epoch 38/40\n",
      "28/28 [==============================] - 16s 570ms/step - loss: 0.1845 - accuracy: 0.9423 - val_loss: 1.1004 - val_accuracy: 0.7488\n",
      "Epoch 39/40\n",
      "28/28 [==============================] - 19s 677ms/step - loss: 0.1861 - accuracy: 0.9411 - val_loss: 0.8691 - val_accuracy: 0.8000\n",
      "Epoch 40/40\n",
      "28/28 [==============================] - 16s 560ms/step - loss: 0.1685 - accuracy: 0.9400 - val_loss: 1.1358 - val_accuracy: 0.7814\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, validation_data=X_val, epochs=40, batch_size=32 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BM4XoUSD1Lgw",
    "outputId": "51d9876d-ca31-4a7b-b63f-c55a636ee67d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/15 [=======================>......] - ETA: 2s - loss: 0.7264 - accuracy: 0.8594"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 11 bytes but only got 10. Skipping tag 42037\n",
      "  \" Skipping tag %s\" % (size, len(data), tag)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 13s 895ms/step - loss: 0.7955 - accuracy: 0.8489\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7954535484313965, 0.848936140537262]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "99UTgULxFMNB",
    "outputId": "2cd5e35e-412e-4976-b696-c8ea09d786b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"custom_cnnmodel.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"custom_cnnmodel.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
